{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: '/similarity_metrics/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kubov\\Documents\\git_projects\\similarity_metrics\\example.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kubov/Documents/git_projects/similarity_metrics/example.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# !pip install h5py\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kubov/Documents/git_projects/similarity_metrics/example.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#!git clone https://github.com/JVrabel/similarity_metrics.git\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kubov/Documents/git_projects/similarity_metrics/example.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kubov/Documents/git_projects/similarity_metrics/example.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39;49mchdir(\u001b[39m'\u001b[39;49m\u001b[39m/similarity_metrics/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: '/similarity_metrics/'"
     ]
    }
   ],
   "source": [
    "# !pip install h5py\n",
    "#!git clone https://github.com/JVrabel/similarity_metrics.git\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.chdir('/content/similarity_metrics/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from src.load_libs_data import load_h5_data\n",
    "\n",
    "spectra, metadata = load_h5_data('datasets/chemcam_extended2015_v_a.h5')\n",
    "wavelengths = spectra.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = metadata.loc[:,'SiO2':'K2O']\n",
    "ground_truth = ground_truth.drop(['FeT', 'FeO', 'Fe2O3'] , axis = 1)\n",
    "ground_truth = ground_truth.drop(ground_truth.columns[[3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x129baed6df0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = wavelengths\n",
    "differences = [x[i+1]-x[i] for i in range(len(x)-1)]\n",
    "\n",
    "unique_differences = list(set(differences))\n",
    "wavelengths\n",
    "plt.plot(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ech_grid = np.arange(200.00, 1000.00, 0.02)\n",
    "ech_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "ech_grid = np.arange(200.00, 1000.00, 0.02)\n",
    "ech_grid.shape\n",
    "\n",
    "\n",
    "mask_bound = ~((ech_grid >= wavelengths.min()) & (ech_grid <= wavelengths.max()))\n",
    "mask_1gap = (ech_grid >= 339) & (ech_grid <= 383)\n",
    "mask_2gap = (ech_grid >= 468) & (ech_grid <= 474)\n",
    "mask = mask_bound | mask_1gap | mask_2gap\n",
    "\n",
    "# mask_plot = 1*mask \n",
    "# plt.plot(mask_plot)\n",
    "ech_grid = ech_grid[~mask]\n",
    "\n",
    "# interpolate the signal to the new time grid using linear interpolation\n",
    "f = interp1d(wavelengths, spectra, kind='linear')\n",
    "spectra_ech = f(ech_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization import plot_spectra\n",
    "\n",
    "names = ground_truth.index.values.tolist()\n",
    "plot_spectra(spectra_ech[:20,:], ech_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import efficiency_fcn, relu\n",
    "from src.visualization import plot_one_spectrum\n",
    "\n",
    "eff = efficiency_fcn(x = ech_grid, x0 = 250, A=1, k=0.008)\n",
    "eff = relu(eff)\n",
    "plot_one_spectrum(eff,ech_grid, title = \"efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_spectra_ech = eff*spectra_ech\n",
    "plot_spectra(corrected_spectra_ech[:20,:], ech_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1036: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=8.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Replace NaNs with zeros\n",
    "data = ground_truth.fillna(0)\n",
    "\n",
    "# Standardize data\n",
    "standardized_data = (data - data.mean()) / data.std()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute SSE for different values of k\n",
    "sse = []\n",
    "for k in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(standardized_data)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Plot SSE vs. number of clusters\n",
    "plt.plot(range(1, 21), sse)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA of composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Replace NaNs with zeros\n",
    "data = ground_truth.fillna(0)\n",
    "\n",
    "# Standardize data\n",
    "standardized_data = (data - data.mean(axis = 0))/ data.std(axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=11, random_state=42)\n",
    "labels = kmeans.fit_predict(standardized_data)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(standardized_data)\n",
    "\n",
    "# Create scores plot\n",
    "scores = pca.transform(standardized_data)\n",
    "scores_df = pd.DataFrame(scores, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9'])\n",
    "scores_df['Cluster'] = labels.astype(str)\n",
    "scores_fig = px.scatter(scores_df, x='PC1', y='PC2', color='Cluster')\n",
    "\n",
    "# Create loadings plot\n",
    "loadings = pca.components_.T\n",
    "loadings_df = pd.DataFrame(loadings, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9'], index=data.columns)\n",
    "loadings_fig = go.Figure(data=[go.Bar(x=loadings_df.index, y=loadings_df['PC1'])])\n",
    "loadings_fig.update_layout(xaxis_tickangle=-90)\n",
    "\n",
    "# Show plots\n",
    "scores_fig.show()\n",
    "loadings_fig.show()\n",
    "\n",
    "# Count the number of samples in each cluster\n",
    "counts = pd.Series(kmeans.labels_).value_counts()\n",
    "print(counts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 15.9 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.1/133.1 kB 8.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.10.5-py3-none-any.whl (10 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 16.3 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.2-cp310-cp310-win_amd64.whl (16 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.2 filelock-3.10.5 jinja2-3.1.2 mpmath-1.3.0 networkx-3.0 sympy-1.11.1 torch-2.0.0 typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "# np.save(\"datasets/corrected_chemcam_spectra.npy\", corrected_spectra_ech)\n",
    "# np.save(\"datasets/ech_grid_reduced.npy\", ech_grid)\n",
    "# np.save(\"datasets/labels.npy\", labels)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "corrected_spectra_ech = np.load(\"datasets/corrected_chemcam_spectra.npy\")\n",
    "ech_grid = np.load(\"datasets/ech_grid_reduced.npy\")\n",
    "labels = np.load(\"datasets/labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corrected_spectra_ech, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "# del X, y, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if True:\n",
    "  scaler =  Normalizer(norm = 'max')\n",
    "  X_train = scaler.fit_transform(X_train)\n",
    "  X_test = scaler.fit_transform(X_test)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1506, 30735)\n",
      "(377, 30735)\n",
      "(1506,)\n",
      "(377,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.siamese_net import prepare_triplets, prepare_balanced_triplets\n",
    "\n",
    "X_train = torch.from_numpy(X_train).unsqueeze(1).float() # Add extra dimension for channels\n",
    "X_test = torch.from_numpy(X_test).unsqueeze(1).float() # Add extra dimension for channels\n",
    "y_train = torch.from_numpy(np.array(y_train)).long()\n",
    "y_test = torch.from_numpy(np.array(y_test)).long()\n",
    "\n",
    "#X_test_shifted = torch.from_numpy(X_test_shifted).unsqueeze(1).float() # Add extra dimension for channels\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train.to(device)\n",
    "X_test.to(device) \n",
    "y_train.to(device)\n",
    "y_test.to(device)\n",
    "\n",
    "# Prepare triplets for the training, validation, and test sets\n",
    "train_triplets = prepare_triplets(X_train, y_train)\n",
    "val_triplets = prepare_triplets(X_test, y_test)\n",
    "test_triplets = prepare_triplets(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Create PyTorch DataLoader objects for the training, validation, and test sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_triplets, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_triplets, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_triplets, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import funcs\n",
    "# import importlib\n",
    "# importlib.reload(funcs)\n",
    "# from funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseNetwork(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv1d(1, 50, kernel_size=(50,), stride=(2,), padding=(1,))\n",
      "    (1): Conv1d(50, 50, kernel_size=(10,), stride=(2,), padding=(1,))\n",
      "  )\n",
      "  (relu_layers): ModuleList(\n",
      "    (0-1): 2 x ReLU()\n",
      "  )\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=383450, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (relu_fc_layers): ModuleList(\n",
      "    (0): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import wandb\n",
    "from src.siamese_net import SiameseNetwork\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize a new WandB run\n",
    "# wandb.init(project='siamese_net_chemcam', entity='jakubv')\n",
    "\n",
    "margin = 1.0\n",
    "\n",
    "# Define the number of epochs and batch size\n",
    "num_epochs = 1\n",
    "input_size = X_train.shape[2]\n",
    "output_size = 10\n",
    "channels=50\n",
    "kernel_sizes=[50, 10]\n",
    "strides=[2, 2]\n",
    "paddings=[1, 1]\n",
    "hidden_sizes=[256]\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "# Instantiate the Siamese network, optimizer, and loss function\n",
    "#net = SiameseNetwork()\n",
    "net = SiameseNetwork(input_size=input_size, output_size=output_size, channels=channels, kernel_sizes=kernel_sizes, strides=strides, paddings=paddings, hidden_sizes=hidden_sizes)\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "criterion = nn.TripletMarginLoss(margin=margin)\n",
    "\n",
    "\n",
    "net.to(device)\n",
    "print(net)\n",
    "\n",
    "# wandb.watch(net)\n",
    "\n",
    "# # Train the network\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Set the network to training mode\n",
    "#     net.train()\n",
    "\n",
    "#     # Initialize running loss and number of batches for the training dataset\n",
    "#     running_loss_train = 0.0\n",
    "#     num_batches_train = 0\n",
    "\n",
    "#     # Iterate over the training data loader\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         # Get the inputs and labels for the current batch\n",
    "#         inputs = [input.to(device) for input in data]\n",
    "        \n",
    "#         input_a = inputs[0]\n",
    "#         input_p = inputs[1]\n",
    "#         input_n = inputs[2]\n",
    "        \n",
    "#         # Compute the embeddings for the current batch\n",
    "#         outputs = net(input_a, input_p, input_n)\n",
    "\n",
    "\n",
    "#         # Split the embeddings into anchor, positive, and negative examples\n",
    "#         anchor = outputs[0]\n",
    "#         positive = outputs[1]\n",
    "#         negative = outputs[2]\n",
    "        \n",
    "#         # Compute the triplet loss for the current batch\n",
    "#         loss_train = criterion(anchor, positive, negative)\n",
    "\n",
    "#         # Backpropagate the loss and update the network parameters\n",
    "#         loss_train.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Update the running loss and number of batches for the training dataset\n",
    "#         running_loss_train += loss_train.item()\n",
    "#         num_batches_train += 1\n",
    "\n",
    "#     # Compute the average loss for the training dataset\n",
    "#     epoch_loss_train = running_loss_train / num_batches_train\n",
    "\n",
    "#     # Set the network to evaluation mode\n",
    "#     net.eval()\n",
    "\n",
    "#     # Initialize running loss and number of batches for the validation dataset\n",
    "#     running_loss_val = 0.0\n",
    "#     num_batches_val = 0\n",
    "\n",
    "#     # Iterate over the validation data loader\n",
    "#     for i, data in enumerate(val_loader, 0):\n",
    "#         # Get the inputs and labels for the current batch\n",
    "        \n",
    "#         inputs_val = [input.to(device) for input in data]\n",
    "        \n",
    "#         input_a = inputs_val[0]\n",
    "#         input_p = inputs_val[1]\n",
    "#         input_n = inputs_val[2]\n",
    "#         # Compute the embeddings for the current batch\n",
    "#         outputs = net(input_a, input_p, input_n)\n",
    "\n",
    "#         # Split the embeddings into anchor, positive, and negative examples\n",
    "#         anchor = outputs[0]\n",
    "#         positive = outputs[1]\n",
    "#         negative = outputs[2]\n",
    "        \n",
    "#         # Compute the triplet loss for the current batch\n",
    "#         loss_val = criterion(anchor, positive, negative)\n",
    "\n",
    "#         # Update the running loss and number of batches for the validation dataset\n",
    "#         running_loss_val += loss_val.item()\n",
    "#         num_batches_val += 1\n",
    "\n",
    "#     # Compute the average loss for the validation dataset\n",
    "#     epoch_loss_val = running_loss_val / num_batches_val\n",
    "\n",
    "#     # Log the loss values to your WandB run\n",
    "#     # wandb.log({\n",
    "#     #     \"epoch\": epoch+1,\n",
    "#     #     \"training_loss\": epoch_loss_train, \n",
    "#     #     \"validation_loss\": epoch_loss_val\n",
    "#     #     })\n",
    "\n",
    "#     # Print the epoch number, training loss, and validation loss\n",
    "#     print('Epoch [{}/{}], Training Loss: {:.4f}, Validation Loss {:.4f}'.format(epoch+1, num_epochs, epoch_loss_train, epoch_loss_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = torch.randn(1, 1, 30735)\n",
    "# x = x.to(device)\n",
    "\n",
    "\n",
    "# #torch.onnx.export(net, (x,x,x), \"onnx-ized.onnx\", export_params=True)\n",
    "# # wandb.save('onnx-ized.onnx')\n",
    "# # End the WandB run\n",
    "# # wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Serving 'model.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install netron\n",
    "# !pip install onnx\n",
    "\n",
    "import netron\n",
    "\n",
    "input_dummy = torch.randn(1, 1, 30735)\n",
    "input_dummy = input_dummy.to(device)\n",
    "\n",
    "\n",
    "torch.onnx.export(net, (input_dummy,input_dummy,input_dummy), \"model.onnx\", export_params=False)\n",
    "\n",
    "\n",
    "input_dummy = torch.randn(1, 1, 30735)\n",
    "input_dummy = input_dummy.to(device)\n",
    "\n",
    "netron.start(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SiameseNetwork                           [1, 10]                   --\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-1                       [1, 50, 15344]            2,550\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-2                         [1, 50, 15344]            --\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-3                       [1, 50, 7669]             25,050\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-4                         [1, 50, 7669]             --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-5                       [1, 256]                  98,163,456\n",
       "├─ModuleList: 1-20                       --                        --\n",
       "│    └─ReLU: 2-6                         [1, 256]                  --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-7                       [1, 10]                   2,570\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-8                       [1, 50, 15344]            (recursive)\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-9                         [1, 50, 15344]            --\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-10                      [1, 50, 7669]             (recursive)\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-11                        [1, 50, 7669]             --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-12                      [1, 256]                  (recursive)\n",
       "├─ModuleList: 1-20                       --                        --\n",
       "│    └─ReLU: 2-13                        [1, 256]                  --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-14                      [1, 10]                   (recursive)\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-15                      [1, 50, 15344]            (recursive)\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-16                        [1, 50, 15344]            --\n",
       "├─ModuleList: 1-17                       --                        (recursive)\n",
       "│    └─Conv1d: 2-17                      [1, 50, 7669]             (recursive)\n",
       "├─ModuleList: 1-18                       --                        --\n",
       "│    └─ReLU: 2-18                        [1, 50, 7669]             --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-19                      [1, 256]                  (recursive)\n",
       "├─ModuleList: 1-20                       --                        --\n",
       "│    └─ReLU: 2-20                        [1, 256]                  --\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─Linear: 2-21                      [1, 10]                   (recursive)\n",
       "==========================================================================================\n",
       "Total params: 98,193,626\n",
       "Trainable params: 98,193,626\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 988.21\n",
       "==========================================================================================\n",
       "Input size (MB): 0.37\n",
       "Forward/backward pass size (MB): 27.62\n",
       "Params size (MB): 392.77\n",
       "Estimated Total Size (MB): 420.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install torchinfo\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(net, [(1, 1, 30735), (1, 1, 30735), (1, 1, 30735)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30735\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_sizes = [256,128, 64]\n",
    "for i in range(len(hidden_sizes)):\n",
    "    if i == 0:    \n",
    "        print(input_size)\n",
    "        print(hidden_sizes[i])\n",
    "    else:\n",
    "        print(hidden_sizes[i-1])\n",
    "        print(hidden_sizes[i])\n",
    "hidden_sizes[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.siamese_net import SiameseNetwork\n",
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "\n",
    "# margin = 1.0\n",
    "\n",
    "# # Define the number of epochs and batch size\n",
    "# num_epochs = 10\n",
    "# input_size = X_train.shape[2]\n",
    "# output_size = 10\n",
    "# channels=50\n",
    "# kernel_sizes=[50, 10]\n",
    "# strides=[2, 2]\n",
    "# paddings=[1, 1]\n",
    "# hidden_sizes=[256, 128]\n",
    "# learning_rate = 1e-4\n",
    "\n",
    "\n",
    "# # Instantiate the Siamese network, optimizer, and loss function\n",
    "# #net = SiameseNetwork()\n",
    "# net = SiameseNetwork(input_size=input_size, output_size=output_size, channels=channels, kernel_sizes=kernel_sizes, strides=strides, paddings=paddings, hidden_sizes=hidden_sizes)\n",
    "# optimizer = optim.Adam(net.parameters(), lr = learning_rate)\n",
    "# criterion = nn.TripletMarginLoss(margin=margin)\n",
    "\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# # Train the network\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Set the network to training mode\n",
    "#     net.train()\n",
    "\n",
    "#     # Initialize running loss and number of batches for the training dataset\n",
    "#     running_loss_train = 0.0\n",
    "#     num_batches_train = 0\n",
    "\n",
    "#     # Iterate over the training data loader\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         # Get the inputs and labels for the current batch\n",
    "#         inputs = [input.to(device) for input in data]\n",
    "        \n",
    "#         input_a = inputs[0]\n",
    "#         input_p = inputs[1]\n",
    "#         input_n = inputs[2]\n",
    "        \n",
    "#         # Compute the embeddings for the current batch\n",
    "#         outputs = net(input_a, input_p, input_n)\n",
    "\n",
    "\n",
    "#         # Split the embeddings into anchor, positive, and negative examples\n",
    "#         anchor = outputs[0]\n",
    "#         positive = outputs[1]\n",
    "#         negative = outputs[2]\n",
    "        \n",
    "#         # Compute the triplet loss for the current batch\n",
    "#         loss_train = criterion(anchor, positive, negative)\n",
    "\n",
    "#         # Backpropagate the loss and update the network parameters\n",
    "#         loss_train.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Update the running loss and number of batches for the training dataset\n",
    "#         running_loss_train += loss_train.item()\n",
    "#         num_batches_train += 1\n",
    "\n",
    "#     # Compute the average loss for the training dataset\n",
    "#     epoch_loss_train = running_loss_train / num_batches_train\n",
    "\n",
    "#     # Set the network to evaluation mode\n",
    "#     net.eval()\n",
    "\n",
    "#     # Initialize running loss and number of batches for the validation dataset\n",
    "#     running_loss_val = 0.0\n",
    "#     num_batches_val = 0\n",
    "\n",
    "#     # Iterate over the validation data loader\n",
    "#     for i, data in enumerate(val_loader, 0):\n",
    "#         # Get the inputs and labels for the current batch\n",
    "        \n",
    "#         inputs_val = [input.to(device) for input in data]\n",
    "        \n",
    "#         input_a = inputs_val[0]\n",
    "#         input_p = inputs_val[1]\n",
    "#         input_n = inputs_val[2]\n",
    "#         # Compute the embeddings for the current batch\n",
    "#         outputs = net(input_a, input_p, input_n)\n",
    "\n",
    "#         # Split the embeddings into anchor, positive, and negative examples\n",
    "#         anchor = outputs[0]\n",
    "#         positive = outputs[1]\n",
    "#         negative = outputs[2]\n",
    "        \n",
    "#         # Compute the triplet loss for the current batch\n",
    "#         loss_val = criterion(anchor, positive, negative)\n",
    "\n",
    "#         # Update the running loss and number of batches for the validation dataset\n",
    "#         running_loss_val += loss_val.item()\n",
    "#         num_batches_val += 1\n",
    "\n",
    "#     # Compute the average loss for the validation dataset\n",
    "#     epoch_loss_val = running_loss_val / num_batches_val\n",
    "\n",
    "#     # Print the epoch number, training loss, and validation loss\n",
    "#     print('Epoch [{}/{}], Training Loss: {:.4f}, Validation Loss {:.4f}'.format(epoch+1, num_epochs, epoch_loss_train, epoch_loss_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu117\n",
    "\n",
    "\n",
    "\n",
    "# import wandb\n",
    "\n",
    "# wandb.login()\n",
    "\n",
    "\n",
    "\n",
    "# config = dict(\n",
    "#     learning_rate = learning_rate,\n",
    "#     epochs = num_epochs,\n",
    "#     classes = output_size,\n",
    "#     kernels = kernel_sizes,\n",
    "#     hidden_layers = hidden_sizes,\n",
    "#     batch = batch_size,\n",
    "#     dataset = \"ChemCam\",\n",
    "#     architecture = \"Siamese CNN\")\n",
    "\n",
    "\n",
    "# def model_pipeline(hyperparameters):\n",
    "\n",
    "#     # tell wandb to get started\n",
    "#     with wandb.init(project=\"pytorch-demo\", config=hyperparameters):\n",
    "#       # access all HPs through wandb.config, so logging matches execution!\n",
    "#       config = wandb.config\n",
    "\n",
    "#       # make the model, data, and optimization problem\n",
    "#       model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "#       print(model)\n",
    "\n",
    "#       # and use them to train the model\n",
    "#       train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "#       # and test its final performance\n",
    "#       test(model, test_loader)\n",
    "\n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
